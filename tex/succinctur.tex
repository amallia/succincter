\documentclass{article}
% Change "article" to "report" to get rid of page number on title page
\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{setspace}
\usepackage{Tabbing}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{extramarks}
\usepackage{chngpage}
\usepackage{soul,color}
\usepackage{graphicx,float,wrapfig}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\usepackage[section]{placeins}
\usepackage{afterpage}


\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}

% In case you need to adjust margins:
\topmargin=-0.45in      %
\evensidemargin=0in     %
\oddsidemargin=0in      %
\textwidth=6.5in        %
\textheight=9.0in       %
\headsep=0.25in         %

\setlength{\parindent}{1cm}


\lstset{language=C,tabsize=3,frame=lines,keywordstyle=\color{blue},commentstyle=\color{purple},stringstyle=\color{red},numbers=left,numberstyle=\tiny,numbersep=5pt,breaklines=true,showstringspaces=false,basicstyle=\footnotesize,emph={label}}


% Document Specific Information
\newcommand{\Title}{Succincter}
\newcommand{\Date}{Tuesday,\ December\ 11,\ 2012}
\newcommand{\Class}{Computer Science 222}
\newcommand{\ClassTime}{}
\newcommand{\ClassInstructor}{Professor Mitzenmacher}
\newcommand{\AuthorName}{Dan Bradley (dbradley@college), Saagar Deshpande (sdeshpande@college)}

% Setup the header and footer
\pagestyle{fancy}                                                       %
\lhead{Bradley, Deshpande}                                                 %
%\chead{\Class\ (\ClassInstructor\ \ClassTime): \Title}  %
\chead{\Title}  %
\rhead{\Date}                                                     %
\lfoot{\lastxmark \Class}                                                      %
\cfoot{}                                                                %
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}}                          %
\renewcommand\headrulewidth{0.4pt}                                      %
\renewcommand\footrulewidth{0.4pt}                                      %

% This is used to trace down (pin point) problems
% in latexing a document:
%\tracingall


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Make title
\title{\textmd{\textbf{\Class:\ \Title}}\\\normalsize\vspace{0.1in}\small{ \Date}\\\vspace{0.1in}\large{\textit{\ClassInstructor\ \ClassTime}}}
\author{\textbf{\AuthorName}}
\date{Final Project}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%\tableofcontents

\bigskip
\centerline{**********}

\noindent \section{Abstract}
Using Mihai Patrascu's 2008 paper "Succincter" [1],  we implement a way to store trits (trinary values) within 1.01\% of the ideal space of $n*log_2(3)$ while having lookup in $O(t)$ time, where $t$ is the depth of our data structure. We use recursion to improve redundancy in the data structure, which allows us to accurately compute single decodes quickly without needing to decode the entire compressed block first. We find that this is both a fast and space efficient robust data structure for encoding and decoding operations with room for extension past simply storing trits.\\

\noindent \section{Introduction}

\indent There are few effective methods for storing trits. In this paper, we focus on three of them: the naive method, arithmetic coding, and our succincter implementation.\\

\indent The naive method is simple. As a trit has more information than a bit, but less than two bits, store each trit using two bits. Obviously this is not the most space-efficient method, you could encode $\frac{4}{3}$ as much information in the same space, so it is clearly wasteful. It is however, very fast, both on encode and decode. Encode is strictly linear, with very small constants. The encoder we used took 3.9 milliseconds to encode 500000 entries, and 13.7 milliseconds to decode 500000 entries.\\

\indent Arithmetic coding is much more effective at reducing size. By reducing the entries to one number, we can encode in exactly $\lceil \frac{n*log_2(3)}{8}\rceil$ bytes. Decoding, however, ideally takes linear time, as to reach any original entry, you must go through every entry prior, there is no way to randomly access any element. Furthermore, the nature of arithmetic coding lends itself to manipulation of large numbers, which is time consuming.\\

\indent The succincter data structure is a recursive approach to the problem, and attempts to approach the ideal space usage without sacrificing on decoding time, especially for individual entries. Essentially, succinter takes an array of entries, and breaks them into blocks. These blocks are each treated as one large number, base $K$ (in the first level of the structure when storing trits $K$ is 3, but $K$ changes by level). These large number are then divided by $2^M$ where $M$ is a user-defined variable. The remainder is stored for transmission, and the quotient gets passed up to the next level of the data structure as a new array. The quotient will be some number $\{0 , 1, 2, ... , K -1\}$, and so we can repeat the process on the new array by simply finding new blocks and treating them as numbers base $K$.\\

\indent Mihai Patrascu outlined the idea of succinter data structures in [1], but we took some liberties with our implementation, as his approaches to finding block size and $K$ proved less useful in practice than they might have been in theory.\\

\noindent \section{Implementation}
\noindent \subsection{Encoding}
To encode, we start with an array with fixed size of trits with pseudorandomly assigned values. For the sake of simplicity, and the fact that the values of the trits do not particularly matter for our inquiry, we used the $c$ standard library rand() function seeded by the time of running. \\

We also decided that all remainders would be up to 32 bits long, which for the sake of discussion we will refer to as $M$.\\

With the size of the array and the base 3, we construct the necessary headers to be used by the decoder, specifically the size of the array at that level, the base at that level, and the block size at that level. \\

Given the size and base, the header of all levels are constructable. We are trying to fill an array of size LEVELS (an arbitrary constant we the user decide) + 1 with the size for that level, the block size fro that level, and the base for that level. In the context of this paper, we will call this array headers. We find an $n$ such that our new $K = \lceil \frac{3^n}{2^M} \rceil > 2$. $n$ is the block size for the level, the base for the level is the old $K$, and the size for the level is the old size. The variables then update, with old $K$ being set to new $K$, size decreasing by a factor chunksize, and we are back where we started, just a level higher up the headers.\\

Once the headers are found, we can begin to encode the actual data. We encode recursively, starting from the bottom level = 0 and continuing until level equals LEVELS. To encode, we are given an array to encode, we take the first headers[level].chunksize entries, and combine them into one large number. We then divide by $2^M$, store the remainder, and pass the quotient to a new array we're building for the next level. We do this for each block, and when we reach the end of our entries, we call decode again, on the new array, with level increased.\\

Eventually level will equal LEVELS, and when it does, we naively code the array: we figure out how many bits it takes to completely store a number base $K$, and store each number in the array using that many bits. \\

We put in an output file the SIZE, LEVELS, and M, write all the headers to the file, then write out all the bits for the last level of storage. \\

\noindent Encode(array, level):\\
$if (level = LEVELS$ $OR$ $headers[level].size = 1)\\
\indent encode\_last(array, headers[level]);\\
counter = 0;\\
index = 0;\\
new\_array[];\\
string total;\\
while(counter < headers[level].size)\\
\indent for (int i = 0; i < headers[level].chunksize; i++)\\
\indent \indent total[i] = array[counter];\\
\indent \indent counter++;\\
\indent number = num\_from\_string(total, base$ $h.K);\\
\indent number = number / 2^M;\\
\indent new\_array[index] = number / 2^M;\\
\indent m = number \% 2^M;\\
\indent fwrite(output, m);\\
\indent index++;\\
return$ $Encode(new\_array, level + 1);$\\\\\\

\noindent Encode\_last(array, header):\\
$counter = 0;\\
while (header.K > 0)\\
\indent header.K = header.K / 2;\\
\indent counter++;\\
cycler = 1;\\
byte = 0;\\
for(i = 0; i < header.size; i++)\\
\indent k = 1;\\
\indent for(j = 0; j < counter; j++)\\
\indent \indent if(k \& array[i])\\
\indent \indent \indent byte = byte | cycler;\\
\indent \indent k = 2*k;\\
\indent \indent cycler = 2*cycler;\\
\indent \indent if (cycler = 2^8)\\
\indent \indent \indent fwrite(output, byte);\\
\indent \indent \indent byte = 0;\\
\indent \indent \indent cycler = 1;\\
fwrite(output,byte);\\
return;\\$


\noindent \subsection{Decoding}
For both decoding schemes, we first need to read and interpret the input file, which is done essentially in reverse of encoding, taking SIZE, LEVELS, and M to be global variables, as well as the headers array, an array of all the remainders, and the last array that was encoded.\\

\noindent \subsubsection{Decode All}
We are given an array (to start with, the last arrray), and that we are on the highest level, and with that and the global variables, we can decode every original entry in the right order. To do this, we go through the array with index, take the remainder corresponding to the index in and find remainders[current\_level - 1][index] + $2^M$*array[index]. This is the same number we created by amalgamating each block in the encoder. To get the array for the next level down, we simply divide the number by the base of the next level down, and place each remainder in a new array. If we go through the entire array like this, we can traverse the data structure level by level passing new array and the current level, and eventually decode the entire structure. \\

\noindent Decode\_all(array,level):\\
$if(level = 0)\\
\indent print(array);	\\
index = 0;\\
for(i = 0; i < h.size; i++)\\
\indent number = remainders[level-1][i]);\\
\indent number = number + 2^M*array[i];\\	
\indent min = min(headers[level-1].chunksize, headers[level-1].size - index);\\
\indent for(j = 0; j < min; j++)\\
\indent \indent new\_array[index + min - j - 1] = number\%headers[level-1].K;\\
\indent \indent number =  number / headers[level-1].K;\\
\indent index += min;\\
return$ $Decode\_all(new\_array, level - 1);\\$


\noindent \subsubsection{Decode One}
Decoding one value alone is a more complicated process. We need to determine the path of remainders and array values to follow from the highest level to the lowest. 
To do this, we can simply find where in the completely decoded array the item would be, and then by using the headers, we find where in each block the number would be, and where in the highest level's array the object to be decoded is.\\

Once we have the path, it becomes simply a matter of following, instead of building arrays, you only keep the object identified by the path, and decode through there alone. That is why it only takes linear time with respect to the depth of the data structure.\\

\noindent Make\_path(int n):\\
$for(i = 0; i < levels + 1; i++)\\
\indent paths[i].where = n;\\
\indent paths[i].path = n \% headers[i].chunksize;\\
\indent n = n / headers[i].chunksize;$\\

\noindent Decode\_one():\\
$num = final[paths[levels].path];\\
for(i = levels - 1; i >=0; i--) \\
\indent number = remainders[i][paths[i + 1].where];\\
\indent number = number + 2^M*num;\\
\indent for(j = headers[i].chunksize - 1; j > paths[i].path; j--)\\
\indent \indent number = number / headers[i].K;\\
\indent number = number / headers[i].K;\\
\indent num = number;\\
return$ $num;$\\

The full encoding and decoding files are in the Appendix.\\


\bigskip

\noindent \section{Results and Analysis}

We ran our implementation of Succincter on 500000 trits except in the case of individual decoding, where we only use 200000 trits. We compared this implementation against a simple C implementation of arithmetic encoding as well as a naive C implementation of a trit to bit converter, which stores each trit as its corresponding bit.\\

\includegraphics[scale=0.4]{images/betterlevel_v_encode}
\includegraphics[scale=0.4]{images/lvl_encodingsize}
\afterpage{\vfill}

Initially, we compared the speed of encoding and decoding using multiple depths for the data structure as well as the space required for the encoding process. We noticed that the encoding time is relatively similar for each of the depths we run Succincter on, with level 4 edging the others by an insignificant amount. This indicates that the time taken is relatively similar for any depth of structure. One likely reason is the fact that the maximum useful depth is log$(n)$, as we divide the size down each level by the block size, and an array with a size of 1 should just be encoded wasting the one bit. The reason that we see the high levels of encoding to be slightly faster is because the last layer of values need to be specially encoded from their current base to bits. For the lower levels, this is a more expensive process as the number of values left to be specially encoded is much larger. However, this time is still largely insignificant for large sets of values. \\

This reasoning for the encoding time also extends to the average encoding sizes we see in our experimentation. We see that as the level increases, we have an immediate decrease in size from level 1 to level 2, and after that the size remains roughly the same. This likely indicates that the size of the encoded data will remain close to the same for any level past level 1 given this size of input, though it is very possible that with larger inputs higher level caps become more effective. \\

\begin{center}\smallskip
    \begin{tabular}{ | c | c | c | c |}
    \hline
    Level & Avg. Encode Time (sec) & Avg. Decode Time (sec) & Avg. Encode Size (bytes) \\ \hline
    1 & 0.00178906 & 0.043107825396825 & 101229\\
    2 & 0.00177046 & 0.041240047619048 & 100108\\
    3 & 0.00173798 & 0.041672920634921 & 100066\\
    4 & 0.00173344 & 0.041674126984127 & 100076\\
    5 & 0.00175082 & 0.040755396825397 & 100088\\ \hline
    \end{tabular}
\end{center}

\includegraphics[scale=0.4]{images/betterlevel_v_decode}
\includegraphics[scale=0.4]{images/individual_decodetime}
\afterpage{\vfill}

Looking at decoding across each level, we notice that the average decoding times are very similar, with a slight decrease as the level cap increases. The change is too small to be of much statistically interest, leading us to believe that the decode time is essentially the same for each depth on average. We can get a better sense of this by looking at the individual decoding time scatter plot. Here, it appears that in the majority of cases, both level 2 and level 4 decoding are roughly the same time. The red scatter mass on the left and the blue scatter mass on the right seem to be noise in the system. There does seem to be much longer times for level 2 for larger values, and longer times for level 4 on smaller individual values, but a good explanation for why that would be the case is elusive.\\

\includegraphics[scale=0.4]{images/decoding_time}
\includegraphics[scale=0.4]{images/individual_decode_20000}
\afterpage{\vfill}

In general, it appears that decoding is not impacted by the level of encoding used on the input string, and the only factor we will have to worry about when decoding is the the length of the input string. Of some more importance is the time required to decode. We compared the decoding time for the three implementations mentioned earlier, the naive trit to bit translation, the simple arithmetic encoder, and our Succincter model. We noticed that the naive method is definitely the fastest of the three, which intuitively makes sense because each trit is stored in its full bit form. Succincter is within a factor of 3 in speed to the naive decoder; which, while not great, can be seen as a necessary tradeoff for the improved efficiency. This means that we can encode information and store it in a more compact form than the naive method while still having similar decoding times across the entire input. Succincter handles the arithmetic encoder time with ease; it appears that as the length of the input increases, the arithmetic decoder grows in polynomial time, while the Succincter implementation barely grows at all. Because we use similar, or even less, space than the arithmetic encoding scheme, Succincter seems to be a viable replacement for arithmetic encoding if properly implemented. It is also possible however, that our arithmetic encoder was not quite of the same quality, and we could find (or make) one that would be better competition with Succincter. Especially since theoretically, the decode time should be on the same order.\\

\indent The area that Succincter should be asymptotically faster than arithmetic coding is in individual decoding time. Arithmetic coding should run in linear time, while the naive approach and Succincter should be constant time algorithms. Once again, we see that the naive method is the fastest one; for any individual trits, we require no calculation and can simple covert the number of bits we see into trits. Succincter takes 300 times as long, to decode each individual, but still takes less than a millisecond to run. Succincter is able to stay within the constant arithmetic bounds for individual decoding time because of the properties of the spillover algorithm and universe as defined in the Patrascu paper. Arithmetic decoding of individual trits requires the entire string to be decoded first, which seems to end up slowing down the arithmetic decoder a lot, leading to the logarthimic curve seen in the graph above.\\


\includegraphics[scale=0.4]{images/encoding_time}
\includegraphics[scale=0.4]{images/encoding_size}
\afterpage{\vfill}

We also compared the encoding times and encoding sizes of the three approaches. The naive takes the least amount of time to encode, which is obvious as there is no real computation to be done for the encoding process. Succincter is only marginally slower than the naive progress, and it appears that both naive and Succincter have a much small slope of growth when compared to the arithmetic encoder. All three algorithms grow linearly with the size of the input string; this is true because when a new character is presented, we act on it when it appears, so we only need to read the input string one time for each implementation in order to encode it. Based on encoding time, Succincter beats arithmetic encoding by more than a factor of two on average, and naive encoding beats Succincter by more than a factor of two on average.\\

When we look at the encoding size, it is immediately apparent that the naive approach requires the most space. Each trit in the string is stored in its entirety as bits, so there is no change to encode and compress the information. When we compare Succincter and arithmetic coding, both are better compressed than naive, with Succincter just slightly performing better at longer string lengths. \\

Looking just at encoding time and size, we see that Succincter is an effective algorithm to use. In terms of encoding time, Succincter is comparable, though worse to the faster naive implementation, while in terms of encoding size, Succincter is comparable to the arithmetic encoder implementation. \\

\noindent \section{Conclusion}

Succincter seems like an effective algorithm to use for while naive implementation is much faster on the whole, there are obviously data sets where Succincter could prove useful. Datasets that have plenty of space and need to be fast would be better served by using the naive approach, though the space limited user should use Succincter. Succincter allows us to have both speed and compression without major losses of one or the other. Furthermore, looking at decode time, Succincter has relatively quick decoding times for both the entire string and for individual decoding. The individual decoding aspect makes Succincter especially powerful because it is now possible to look up any single trit in the string without having to spend the total time to decode the entire encoded string. Arithmetic decoders require the entire encoded string to be decoded before an answer can be found; this is not true with Succincter.\\

Additional steps to be taken are clearly test to our structure against a better arithmetic encoder, and see how the times compare. Spacewise, even a perfect arithmetic encoder could not improve much on our structure, as the ideal $n*log_2(3)$ space for $n = 500000$ is 99060 bytes; Succincter used 100066 bytes. Our time comparisons however, do not accurately represent a fully functioning arithmetic encoder, and so to understand the true utility of the structure, it would be useful to have an upper time bound.\\

Further (assuming this structure does stand the test of time) it can be applied to any time an arithmetic coder could be used. Assuming the arithmetic encoder uses rational numbers for its probabilities, the lowest common denominator of the probabilities could be used as the base for the first level of the data structure. Take the example where the probabilities are ('a' = .4,  'b' = .1, 'c' = .5). Multiplying by ten, it's clear these numbers could all be treated as numbers base ten, ('a' = 0,1,2,3, 'b' = 4, 'c' = 5,6,7,8,9). So to encode, take the integer values of the string as the initial array, and the size to be the length of the string, and with that you can encode and decode just as effectively as with arithmetic encoding.\\

\bigskip
\centerline{**********}
\noindent \section{Acknowledgements}
	We would like to thank Micheal Mitzenmacher for inspiring this project.

\bigskip
\centerline{**********}

\noindent \section{References}
Patrascu, Mihai. Succincter. 49th IEEE Symposium on Foundations of Computer Science. 2008.

\noindent \section{Appendix}
\noindent \subsection{Succincter Code}

\lstinputlisting[language=C,label=encoder,caption=Succincter Encoder]{../succinct_code/encoder.c}

\lstinputlisting[language=C,label=decoder,caption=Succincter Decoder]{../succinct_code/decoder.c}

\noindent \subsection{Full Size Images}
\includegraphics[scale=0.8]{images/betterlevel_v_encode}\\
\includegraphics[scale=0.8]{images/lvl_encodingsize}\\
\includegraphics[scale=0.8]{images/betterlevel_v_decode}\\
\includegraphics[scale=0.8]{images/individual_decodetime}\\
\includegraphics[scale=0.8]{images/decoding_time}\\
\includegraphics[scale=0.8]{images/individual_decode_20000}\\
\includegraphics[scale=0.8]{images/encoding_time}\\
\includegraphics[scale=0.8]{images/encoding_size}\\

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

